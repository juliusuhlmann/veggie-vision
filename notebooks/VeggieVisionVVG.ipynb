{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VGG8' from 'tensorflow.keras.applications' (c:\\Users\\juliu\\.conda\\lib\\site-packages\\keras\\api\\_v2\\keras\\applications\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26712\\2632998923.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGG8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'VGG8' from 'tensorflow.keras.applications' (c:\\Users\\juliu\\.conda\\lib\\site-packages\\keras\\api\\_v2\\keras\\applications\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeggieVision:\n",
    "    def __init__(self, base_model, input_shape=(224, 224, 3)):\n",
    "        # Set parameters\n",
    "        self.input_shape = input_shape\n",
    "        self.base_model = base_model\n",
    "        self.model = None\n",
    "        self.datagen = None\n",
    "\n",
    "        # Build the model\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Freeze the base model layers initially\n",
    "        self.base_model.trainable = False\n",
    "\n",
    "       # 2. Build the Model\n",
    "        self.model = models.Sequential()\n",
    "\n",
    "        # Add the base model (MobileNetV2)\n",
    "        self.model.add(self.base_model)\n",
    "\n",
    "        self.model.add(layers.Flatten())\n",
    "\n",
    "        # Add an additional Dense layer with 128 neurons and ReLU activation\n",
    "        self.model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "\n",
    "        self.model.add(layers.Dense(256, activation = \"relu\"))\n",
    "\n",
    "\n",
    "        #   Final Dense layer with a single neuron for regression (predicting weight)\n",
    "        self.model.add(layers.Dense(1, activation='linear'))\n",
    "        \n",
    "\n",
    "    def augment_data(self, X_train):\n",
    "        # 5. Data Augmentation\n",
    "        # Create an ImageDataGenerator for real-time data augmentation\n",
    "        self.datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=180,         # Rotate images by up to 90 degrees\n",
    "            width_shift_range=0.1,     # Shift image horizontally by up to 20% of the width\n",
    "            height_shift_range=0.1,    # Shift image vertically by up to 20% of the height\n",
    "            shear_range=0.1,           # Shear the image by up to 10%\n",
    "            zoom_range=0.1,            # Zoom into the image by up to 20%\n",
    "            horizontal_flip=True,      # Randomly flip images horizontally\n",
    "            fill_mode='nearest'        # Fill in missing pixels with the nearest filled value\n",
    "        )\n",
    "\n",
    "        # Fit the ImageDataGenerator on the training data\n",
    "        self.datagen.fit(X_train)\n",
    "\n",
    "    def fit(self, X, y, batch_size=8, epochs=20, learning_rate=1e-4, validation_split=0.2, fine_tune=False):\n",
    "        # 4. Split Data into Training and Validation Sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, random_state=42)\n",
    "\n",
    "        # Augment the data\n",
    "        self.augment_data(X_train)\n",
    "\n",
    "        # Compile the model with the provided learning rate\n",
    "        self.model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                           loss='mean_squared_error', \n",
    "                           metrics=['mae'])\n",
    "\n",
    "        # 6. Train the Model\n",
    "        # Use the data generator to augment and train the model\n",
    "        history = self.model.fit(self.datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                 validation_data=(X_val, y_val), \n",
    "                                 epochs=epochs)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        test_loss, test_mae = self.model.evaluate(X_val, y_val)\n",
    "        print(f'Test MAE after initial training: {test_mae}')\n",
    "\n",
    "        # 8. Fine-tuning the model (if requested)\n",
    "        if fine_tune:\n",
    "            self.fine_tune(X_train, y_train, X_val, y_val, batch_size, epochs, learning_rate)\n",
    "\n",
    "        return history\n",
    "\n",
    "    def fine_tune(self, X_train, y_train, X_val, y_val, batch_size=32, epochs=10, fine_tune_learning_rate=1e-5):\n",
    "        # Unfreeze the base MobileNetV2 model's layers\n",
    "        self.base_model.trainable = True\n",
    "\n",
    "        # Compile with a lower learning rate for fine-tuning\n",
    "        self.model.compile(optimizer=Adam(learning_rate=fine_tune_learning_rate), \n",
    "                           loss='mean_squared_error', \n",
    "                           metrics=['mae'])\n",
    "\n",
    "        # Fine-tune the model with augmented data\n",
    "        fine_tune_history = self.model.fit(self.datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                           validation_data=(X_val, y_val), \n",
    "                                           epochs=epochs)\n",
    "\n",
    "        # Evaluate after fine-tuning\n",
    "        test_loss, test_mae = self.model.evaluate(X_val, y_val)\n",
    "        print(f'Test MAE after fine-tuning: {test_mae}')\n",
    "\n",
    "        return fine_tune_history\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        test_loss, test_mae = self.model.evaluate(X, y)\n",
    "        print(f'MAE: {test_mae}')\n",
    "        return test_loss, test_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"../data/processed_data/X.npy\")\n",
    "y = np.load(\"../data/processed_data/y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "base_model = VGG8(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "veggiev_bm = VeggieVision(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "73/73 [==============================] - ETA: 0s - loss: 15977.0586 - mae: 56.4971"
     ]
    }
   ],
   "source": [
    "veggiev_bm.fit(X,y, learning_rate = 1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
