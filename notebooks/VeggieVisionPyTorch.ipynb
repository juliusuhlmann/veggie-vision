{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class VeggieDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images  # Should be in (batch, channels, height, width)\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.transpose(self.images[idx], (1, 2, 0))  # Convert (C, H, W) -> (H, W, C)\n",
    "        image = Image.fromarray((image * 255).astype(np.uint8))  # Convert to PIL Image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32).squeeze()\n",
    "        return image, label\n",
    "\n",
    "# Model class\n",
    "class VeggieVision(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VeggieVision, self).__init__()\n",
    "        self.base_model = models.mobilenet_v2(pretrained=True)\n",
    "        self.base_model.features.requires_grad = False  # Freeze base layers\n",
    "        self.fc1 = nn.Linear(self.base_model.last_channel * 7 * 7, 128)  # Adjust input size here\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # Linear output for regression\n",
    "        return x\n",
    "\n",
    "# Data transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(360),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.1)),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Helper function to prepare data loaders\n",
    "def prepare_data_loaders(X, y, validation_split=0.2, batch_size=32):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, random_state=42)\n",
    "    train_dataset = VeggieDataset(X_train, y_train, transform=train_transform)\n",
    "    val_dataset = VeggieDataset(X_val, y_val, transform=test_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Model initialization with scheduler setup\n",
    "def initialize_model(device, learning_rate=1e-4):\n",
    "    model = VeggieVision().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Set up a scheduler that reduces the learning rate on plateau of validation loss\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "    \n",
    "    return model, criterion, optimizer, scheduler\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def training_loop(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=20, print_freq=1):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Train the model\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device, print_freq=print_freq)\n",
    "        \n",
    "        # Validate the model\n",
    "        val_loss = validate(model, val_loader, criterion, device, print_freq=print_freq)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Step the scheduler based on the validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "# Fine-tuning setup\n",
    "def setup_fine_tuning(model, optimizer, learning_rate=1e-5, n_unfreeze_layers=1):\n",
    "    fine_tune(model, n_unfreeze_layers)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "# Fine-tuning loop\n",
    "def fine_tuning_loop(model, train_loader, val_loader, criterion, optimizer, device, fine_tune_epochs=2):\n",
    "    for epoch in range(fine_tune_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        print(f\"Fine-tuning Epoch {epoch+1}/{fine_tune_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, device, print_freq=1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(dataloader)\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        # Print batch loss every `print_freq` batches\n",
    "        if (batch_idx + 1) % print_freq == 0:\n",
    "            print(f\"Batch {batch_idx+1}/{total_batches}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def validate(model, dataloader, criterion, device, print_freq=1):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Print batch loss every `print_freq` batches\n",
    "            if (batch_idx + 1) % print_freq == 0:\n",
    "                print(f\"Validation Batch {batch_idx+1}/{total_batches}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "# Fine-tuning function\n",
    "def fine_tune(model, n_unfreeze_layers=1):\n",
    "    layers = list(model.base_model.features.children())\n",
    "    for layer in layers[-n_unfreeze_layers:]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "    print(f\"Test Loss: {test_loss / len(dataloader.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(X, y, batch_size=32, epochs=20, learning_rate=1e-4, validation_split=0.2, fine_tune_epochs=2):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Prepare data loaders\n",
    "    train_loader, val_loader = prepare_data_loaders(X, y, validation_split, batch_size)\n",
    "    \n",
    "    # Initialize model, loss function, optimizer, and scheduler\n",
    "    model, criterion, optimizer, scheduler = initialize_model(device, learning_rate)\n",
    "    \n",
    "    # Training phase with scheduler\n",
    "    training_loop(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs)\n",
    "\n",
    "    # Fine-tuning phase\n",
    "    optimizer = setup_fine_tuning(model, optimizer, learning_rate=1e-5, n_unfreeze_layers=1)\n",
    "    fine_tuning_loop(model, train_loader, val_loader, criterion, optimizer, device, fine_tune_epochs)\n",
    "\n",
    "    # Evaluation phase\n",
    "    evaluate(model, val_loader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the data\n",
    "X = np.load(\"../data/processed_data/X.npy\")\n",
    "y = np.load(\"../data/processed_data/y.npy\")\n",
    "\n",
    "# Convert X from (batch, height, width, channel) to (batch, channel, height, width)\n",
    "X = np.transpose(X, (0, 3, 1, 2)).astype(np.float32)\n",
    "y = y.reshape(-1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "# Prepare data loaders\n",
    "train_loader, val_loader = prepare_data_loaders(X, y, 0.2, 32)\n",
    "    \n",
    "# Initialize model, loss function, and optimizer\n",
    "model, criterion, optimizer, scheduler = initialize_model(device, 1e-3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Batch 1/19, Loss: 25047.5566\n",
      "Batch 2/19, Loss: 8467.7266\n",
      "Batch 3/19, Loss: 6200.7573\n",
      "Batch 4/19, Loss: 8364.6162\n",
      "Batch 5/19, Loss: 4902.1943\n",
      "Batch 6/19, Loss: 4182.5083\n",
      "Batch 7/19, Loss: 3084.4709\n",
      "Batch 8/19, Loss: 225863.6406\n",
      "Batch 9/19, Loss: 3007.6860\n",
      "Batch 10/19, Loss: 3475.4595\n",
      "Batch 11/19, Loss: 7597.6143\n",
      "Batch 12/19, Loss: 4261.4644\n",
      "Batch 13/19, Loss: 3177.5859\n",
      "Batch 14/19, Loss: 3925.0598\n",
      "Batch 15/19, Loss: 2347.7053\n",
      "Batch 16/19, Loss: 1572.3467\n",
      "Batch 17/19, Loss: 3510.8660\n",
      "Batch 18/19, Loss: 1302.5117\n",
      "Batch 19/19, Loss: 8025.8115\n",
      "Validation Batch 1/5, Loss: 1870.8722\n",
      "Validation Batch 2/5, Loss: 3035.2324\n",
      "Validation Batch 3/5, Loss: 3262.0908\n",
      "Validation Batch 4/5, Loss: 3017.9617\n",
      "Validation Batch 5/5, Loss: 2539.7529\n",
      "Epoch 1/2, Train Loss: 17660.1766, Validation Loss: 2763.3492\n",
      "Epoch 2/2\n",
      "Batch 1/19, Loss: 1331.5555\n",
      "Batch 2/19, Loss: 2090.3718\n",
      "Batch 3/19, Loss: 3085.8027\n",
      "Batch 4/19, Loss: 2452.3711\n",
      "Batch 5/19, Loss: 1825.3107\n",
      "Batch 6/19, Loss: 1465.5109\n",
      "Batch 7/19, Loss: 202770.4219\n",
      "Batch 8/19, Loss: 3262.4656\n",
      "Batch 9/19, Loss: 4582.8853\n",
      "Batch 10/19, Loss: 9247.5947\n",
      "Batch 11/19, Loss: 3307.0188\n",
      "Batch 12/19, Loss: 2049.1270\n",
      "Batch 13/19, Loss: 2671.3818\n",
      "Batch 14/19, Loss: 2578.0127\n",
      "Batch 15/19, Loss: 2976.2695\n",
      "Batch 16/19, Loss: 1467.9733\n",
      "Batch 17/19, Loss: 2061.2971\n",
      "Batch 18/19, Loss: 1322.6876\n",
      "Batch 19/19, Loss: 3959.9099\n",
      "Validation Batch 1/5, Loss: 1798.7478\n",
      "Validation Batch 2/5, Loss: 3032.5488\n",
      "Validation Batch 3/5, Loss: 2108.7910\n",
      "Validation Batch 4/5, Loss: 1734.4318\n",
      "Validation Batch 5/5, Loss: 1137.3861\n",
      "Epoch 2/2, Train Loss: 13782.9061, Validation Loss: 2035.3398\n"
     ]
    }
   ],
   "source": [
    "# Training phase\n",
    "training_loop(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning phase\n",
    "optimizer = setup_fine_tuning(model, optimizer, learning_rate=1e-5, n_unfreeze_layers=1)\n",
    "fine_tuning_loop(model, train_loader, val_loader, criterion, optimizer, device, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation phase\n",
    "evaluate(model, val_loader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
